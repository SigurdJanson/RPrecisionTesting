---
title: "Notes on Reversion Testing"
author: "Jan Seifert"
date: "7-1-2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

source("./ReverseTestChart.R")

```



## Floating Point Precision / Numerical Stability

How can it be that this is true in R?
```{r}
0.1000000000000000055511151231257827021181583404541015625 == 0.1
```

Isn't R supposed to be precise? As a tool for data scientists and statisticians it should be. And, yet, there are many funny examples. Watch this:

```{r}
0.1 + 0.2 == 0.3      # This will be FALSE. You want proof? You got it.
(0.1 + 0.2) - 0.3     # ==>  5.551115e-17
0.2 + 0.1 -0.1 == 0.2 # FALSE again
```

```{r}
sum(c(1, 1e100, 1, -1e100)) # Will be 0, just wait
```

Such phenomena are quite normal when it comes to floating point arithmetic. If we are not careful, we can end up with code that drifts, , and finally breaks away. Hopefully, I can help someone out there to make it easier to (dis-) prove the numeric stability of your code.

Look at some of the sources at the end if you are interesting in finding out more.


## About Epsilons

To explain the issue let me choose a trivial starting point. Integer numbers on a computer are limited to whole numbers. When you work with integer numbers you have a limited precision. Everything between two whole numbers will get lost. If you compute 

```{r}
3 %/% 2
```

you loose 0.5. And of course, if that is not the final result and you need to put this into another transformation the error can increase as you can see here:
```{r}
10 ^ (3 %/% 2)
# ... whereas ...
10 ^ (3 / 2)
```


A computer can only store a limited amount of numbers. And with integers the precision is limited to one because one is the difference between two neighbouring integer values. Let me call that minimum difference between integers the *integer epsilon*. Please note, that I just invented that term. Computer scientists usually do not refer to that as integer epsilon. I merely invent this term for didactic reasons.

![Precision of integer and floating-point numbers compared](.img/Epsilon_Comparison.svg)

We have a similar situation when it comes to floating point numbers. They are stored in a limited amount of memory and have, thus, limited precision. But there are a few important differences compared to integer.

* Integer numbers can exactly represent numbers of the decimal system. The way floating point numbers are stored that is not possible. A number 0.3 cannot be stored exactly as 0.3. It has to be stored as the closest power of two.
* The epsilon between two floating point numbers is not fixed. For all integer numbers the  epsilon is exactly 1. For floating point numbers the epsilon for 1.0 is $2^{-26} \approx 1.5e-8.$. But for 2E20 the epsilon is $2^{14} = 16384$. The epsilon is the of 1.0 is often referred to as the machine epsilon.
* Your "computer" tries to make the best of the situation when doing floating point operations. When you use the computer always truncates decimal places. A floating point algorithm typically uses the nearest available even number.


## Testing logitnorm functions

I wanted to verify the distribution functions of the logit-norm probability distribution. I had several test cases, already. Now I wanted to extend the range of my tests and I had the idea to use the cumulative distribution function CDF and its inverse to test them against each other, like this: ```{r, f.invers(f(x))}```.

These are the functions in question. The logit function is a helper function to transform the normal values according to the logit-norm function.

```{r}
logit <- function( p ) {
  log(p/(1-p))
}

logit.inv <- function( x ) {
  #0.5 * (1 + tanh(0.5*x)) # alternative version that might be more precise
  1/(1+exp(-x))
}

plogitnorm <- function(q, mean = 0, sd = 1, lower.tail = TRUE) { 
  pnorm(logit(q), mean = mean, sd = sd, lower.tail = lower.tail)
}
qlogitnorm <- function(p, mean = 0, sd = 1, lower.tail = TRUE) { 
  logit.inv(qnorm(p, mean = mean, sd = sd, lower.tail = lower.tail))
}
```


### Forward Test: plogitnorm(qlogitnorm(x))

Let us start with a rather rough result just to get a first impression. This function call will give us ```FALSE``` for every value that isn't close to zero. The required tolerance I chose was 2^-26. That is the same value that R uses in it's ```all.equal```.

```{r}
Result <- ReversionTest("qlogitnorm", "plogitnorm", 
                        ToIterate = list(seq(0.05, 0.95, 0.05), 
                                         mean = seq(-50,50,5), 
                                         sd = c(0.1, 1, 10, 20, 50)))
```

```{r echo=FALSE}
plot(Result)
```

That looks terrible! Let us take a closer look. This time we will quantify the difference from zero.
```{r}
Result <- ReversionTest("qlogitnorm", "plogitnorm", 
                        ToIterate = list(seq(0.05, 0.95, 0.05), 
                                         mean = seq(-50,50,5), 
                                         sd = c(0.1, 1, 10, 20, 50)), 
                        DiffFunc = .DeltaEps)
print(Result)
```
The ouput shows that over 30% of the values are not equivalent to zero. The range of the differences to zero goes up to 0.90!!! The following histogram gives us more details. The y axis shows the size of the differences. A number of -4 on the y axis means that the values were smaller that 2^{-4} = 0.0625 (and larger than 2^{-5} = 0.03125). If the function worked perectly, all values would be on the bottommost bar. But that is somewhat unrealistic. Still the picture is disturbing.

```{r echo=FALSE}
hist(Result)
```

Another plot shows us how the lack of precision is related to the input values of the function. 
```{r echo=FALSE}
plot(Result)
```

Two things are obvious:
1. The bottom part shows the biggest problems. When the mean of the normal distribution is over 30 then it is almost impossible to get useful values. 
2. The zebra pattern is a sign that the combination of mean and sd lead to the problem. A higher sd leads to more errors when the mean is also higher.


### Forward Test: qlogitnorm(plogitnorm(x)) qlogitnorm.subopt

```{r}
Result <- ReversionTest("plogitnorm", "qlogitnorm", 
                        ToIterate = list(seq(0.05, 0.95, 0.05), 
                                         mean = seq(-50,50,5), 
                                         sd = c(0.1, 1, 10, 20, 50)))
```

```{r echo=FALSE}
plot(Result)
```

```{r echo=FALSE}
Result <- ReversionTest("plogitnorm", "qlogitnorm", 
                        ToIterate = list(seq(0.05, 0.95, 0.05), 
                                         mean = seq(-50,50,5), 
                                         sd = c(0.1, 1, 10, 20, 50)),
                        DiffFunc = .DeltaEps)
print(Result)
```


```{r echo=FALSE}
hist(Result)
```

The histogram shows a similar picture.

Another plot shows us how the lack of precision is related to the input values of the function. 
```{r echo=FALSE}
plot(Result)
```

To investigate the issue further we have to take a look at the functions that are called in the logitnorm functions and these are the logit and the normal distribution functions includign their respective inverse.



### The Normal Distribution

```{r}
Result <- ReversionTest("pnorm", "qnorm", 
                        ToIterate = list(seq(-3, +3, 0.4), 
                                         mean = seq(-50,50,5), 
                                         sd = c(0.1, 1, 10, 20, 50)), 
                        DiffFunc = .DeltaEps)
print(Result)
```

The printout tells us there are only a few values above zero and their are still somewhat small. Going the other way round we get a great result. 

```{r}
Result <- ReversionTest("qnorm", "pnorm", 
                        ToIterate = list(seq(0.05, 0.95, 0.05), 
                                         mean = seq(-50,50,5), 
                                         sd = c(0.1, 1, 10, 20, 50)), 
                        DiffFunc = .DeltaEps)
print(Result)
```

All values are near to perfect. The difference between the two roundtrips is understandable. In the first call we ask a lot of the normal functions  because we ask for a value of 3 with a mean of -50. That means we really got to the extremes of the distribution. 

```{r echo=FALSE}
Result <- ReversionTest("pnorm", "qnorm", 
                        ToIterate = list(seq(-3, +3, 0.4), 
                                         mean = seq(-50,50,5), 
                                         sd = c(0.1, 1, 10, 20, 50)), 
                        DiffFunc = .DeltaEps)
print(Result$Data[Result$Data$Delta != 0, ])
```

### The Logit Functions

The normal distribution does not seem to be the cause for the basd performance. That means it's either the logits or the combination of both logit and normal functions.

```{r}
Result <- ReversionTest("logit", "logit.inv", 
                        ToIterate = list(c(2^seq(-100,-1), 1-2^seq(-2,-53))), 
                        DiffFunc = .DeltaEps)
```

The first one is a perfect result. I tried many things to break it. I fed it with values very close to zero, then very close to one. I fed it in many values in tiny steps. The result was immaculate. When I tried it the other way round I stretched the limits even further. In the roundtrip above the logit function returns values ranging around from -69.31 to 36.74. I pushed it even further.

```{r}
Result <- ReversionTest("logit.inv", "logit", 
                        ToIterate = list(seq(32, 38, 0.001)), 
                        DiffFunc = .DeltaEps)
```

These results are not as perfect as before. A round trip of a reversion test is actually not reversible. The results were still great. There was a strange peak of errors in the range from around 30 to 38 and some of those results deviated from the expected values by almost 1%. I might look into that later. For our investigation of the logitnorm functions that does not seem to be the problem. And aside from that strange phenomenon it works great.

```{r echo=FALSE}
print(Result)
plot(Result)
```

I further looked into the range of definition. Mathematically logit is defined for values in the range $]0, 1[$. Practically the function runs into a saturation where varying input values yield no different output anymore. So the real range of logit function as implemented here is $[7.4505 \cdot 10^{-09}, 0.99999999441206455]$. The logit.inv function has a theoretical definition of $[-\infty, \infty]$, but the practical range is between $[-709.7827, 36.7368]$ (values rounded to 4 digits). Especially with the logit.inv it is interesting to note how asymmetric the range is.

```{r echo=FALSE}
#print(SaturationLimit(logit, c(0.5, 0), Limit = -Inf), digits = 20) #0.99999999441206455
#print(SaturationLimit(logit, c(0.5, 0), Limit = -Inf), digits = 20)
#print(SaturationLimit(logit.inv, c(0, -2000), Limit = 0), digits = 20) #-709.7827128964127
#print(SaturationLimit(logit.inv, c(0, 200), Limit = 1), digits = 20)   #36.736800573999062
```

These results give us the important hint. If I define a logit-normal function with the underlying normal distribution having a mean of 50, ```qlogitnorm``` will receive values of 50 and more and feeds that into the logit.inv function. That cannot work when the practical range is limited to values below $36.74$. It would also explain the decrease of precision in the range of input values over 30. The function point algorithms are simply reaching the limits of their precision. Going beyond that logit.inv always returns the same thing and, misleadingly, it appears that high precision has returned.

So, I rewrote the ```logit``` and ```logit.inv``` function to catch this and return ```NA``` (missing value), instead of a meaningless return value from ```logit.inv```.

```{r}
logit <- function( p ) {
  # PRECONDITIONS
  p[p < 7.4505805969238281e-09] <- NA
  p[p > 0.9999999925494194] <- NA
  # CODE
  log(p/(1-p))
}

logit.inv <- function( x ) {
  # PRECONDITIONS
  # Check the range in which logit.inv is defined
  x[x < -745.1332191049] <- NA
  x[x > 37.3827075527515] <- NA
  # CODE
  exp(x) / (exp(x)+1)
}
```


```{r}
Result <- ReversionTest("plogitnorm", "qlogitnorm", 
                        ToIterate = list(seq(0.05, 0.95, 0.05), 
                                         mean = seq(-50,50,5), 
                                         sd = c(0.1, 1, 10, 20, 50)), 
                        DiffFunc = .DeltaEps)
print(Result)
plot(Result)
hist(Result)
```

Now these results are a pretty sight! The errors are almost completely gone. I am very much convinced that I found the problem. 

## Hints on the Implementation

###.NearlyEqual

1. The original code uses ```{c, FLT_MIN}```. According to the C standard this is the minimum normalized positive floating-point number, ```{c, b**(emin - 1)}``` (see ISO/IEC 9899:TC2 5.2.4.2.2/11). In the normalised form there is precisely one non-zero digit in front of the decimal point. According to the [R manuals](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/.Machine) ```{r, .Machine$double.xmin}``` "is the smallest non-zero normalized floating-point number". Hence, that must be the according substitute.
2. The line if ```{c, (a == 0 || b == 0 || (Diff < Float.MIN_NORMAL))}``` is supposedly incorrect. Neither does it make sense nor fits it the description. Therefore, I go with ```{c, if (a == 0 || b == 0 || (absA + absB < Float.MIN_NORMAL))}``` (as suggested by Borgwardt in [the floating point guide](https://floating-point-gui.de/errors/comparison/).



## Sources, References, Further Reading

Mächler (2012) gives further suggestions on how to improve precision. He also shows how to use the Rmpfr package to analyze numeric precision of R functions.

* Mächler, M. (2012) [Accurately Computing log(1−exp(−|a|)). Assessed by the Rmpfr package](https://cran.r-project.org/web/packages/Rmpfr/vignettes/log1mexp-note.pdf)
* Dawson, B. (2012) [Comparing Floating Point Numbers, 2012 Edition](https://randomascii.wordpress.com/2012/02/25/comparing-floating-point-numbers-2012-edition/)
* Morey, R. (2016) [Numerical pitfalls in computing variance](https://www.r-bloggers.com/numerical-pitfalls-in-computing-variance/). accessed at 20200107
* Burns, P. [R Inferno](https://www.burns-stat.com/pages/Tutor/R_inferno.pdf)
* Goldberg, D. (1991) [What Every Computer Scientist Should Know About Floating-Point Arithmetic]( https://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html)
* StackExchange Question ["Solutions for floating point rounding errors"] (https://softwareengineering.stackexchange.com/questions/202843/solutions-for-floating-point-rounding-errors)
* [The Python Tutorial, ch. 15](https://docs.python.org/3/tutorial/floatingpoint.html)
* Rozman, M. G. [floating Point Guide](https://www.phys.uconn.edu/~rozman/Courses/P2200_15F/downloads/floating-point-guide-2015-10-15.pdf)
* Schatz, V. [What you never wanted to know about floating point but will be forced to find out](https://www.volkerschatz.com/science/float.html)



## Further Ideas

Further work probably on speed improvements?
* https://cran.r-project.org/web/packages/doParallel/vignettes/gettingstartedParallel.pdf

